//! # rltbl/rltbl_db

use crate::db_kind::DbKind;

use async_trait::async_trait;
use indexmap::IndexMap;
use lazy_static::lazy_static;
use rand::seq::SliceRandom;
use regex::Regex;
use rust_decimal::Decimal;
use serde::{Deserialize, Serialize};
use serde_json::{Map as JsonMap, json};
use std::{
    collections::{HashMap, HashSet},
    fmt::Display,
    future::Future,
    str::FromStr,
    sync::{Mutex, MutexGuard},
    thread,
    time::Duration,
};
use tree_sitter::{Node, Parser};
use tree_sitter_sequel::LANGUAGE as SQL_LANGUAGE;

pub type JsonValue = serde_json::Value;
pub type JsonRow = JsonMap<String, JsonValue>;
pub type DbRow = IndexMap<String, ParamValue>;
pub type StringRow = IndexMap<String, String>;
pub type ColumnMap = IndexMap<String, String>;

/// Represents a valid database table name.
static VALID_TABLE_NAME_MATCH_STR: &str = r"^[A-Za-z_][0-9A-Za-z_]*$";

/// Default size for the in-memory cache
pub static DEFAULT_MEMORY_CACHE_SIZE: usize = 1000;

lazy_static! {
    /// The regex used to match [valid database table names](VALID_TABLE_NAME_MATCH_STR).
    static ref VALID_TABLE_NAME_REGEX: Regex = Regex::new(VALID_TABLE_NAME_MATCH_STR).unwrap();

    /// The in-memory query cache, used by [CachingStrategy::Memory].
    static ref MEMORY_CACHE: Mutex<HashMap<MemoryCacheKey, Vec<JsonRow>>>
        = Mutex::new(HashMap::new());

    /// The in-memory meta cache. It holds a set of things known to exist.
    static ref MEMORY_META_CACHE: Mutex<HashSet<String>>
        = Mutex::new(HashSet::new());
}

/// Defines the various error types that can be generated by rltbl_db.
#[derive(Clone, Debug)]
#[non_exhaustive] // We may add more specific error types in the future.
pub enum DbError {
    /// An error that occurred while connecting to a database.
    ConnectError(String),
    /// An error in the arguments to a function that accessed the database.
    InputError(String),
    /// An error in the data retrieved from the database.
    DataError(String),
    /// An error that originated from the database.
    DatabaseError(String),
    /// An error with the data type of a value.
    DatatypeError(String),
    /// An error that occurred while attempting to parse a SQL string or value.
    ParseError(String),
}

impl std::error::Error for DbError {}

impl std::fmt::Display for DbError {
    fn fmt(&self, f: &mut std::fmt::Formatter) -> std::fmt::Result {
        match self {
            DbError::ConnectError(err)
            | DbError::DataError(err)
            | DbError::InputError(err)
            | DbError::DatabaseError(err)
            | DbError::DatatypeError(err)
            | DbError::ParseError(err) => write!(f, "{err}"),
        }
    }
}

/// Value types for [query parameters](Params)
#[derive(Debug, Clone, Deserialize, Serialize)]
pub enum ParamValue {
    /// Represents a NULL value. Can be used with any column type.
    Null,
    /// Use with BOOL column types or equivalent.
    Boolean(bool),
    /// Use with INT2 column types or equivalent.
    SmallInteger(i16),
    /// Use with INT4 column types or equivalent.
    Integer(i32),
    /// Use with INT8 column types or equivalent.
    BigInteger(i64),
    /// Use with FLOAT4 column types or equivalent.
    Real(f32),
    /// Use with FLOAT8 column types or equivalent.
    BigReal(f64),
    /// Use with NUMERIC column types or equivalent.
    Numeric(Decimal),
    /// Use with TEXT and VARCHAR column types or equivalent.
    Text(String),
}

// Implementations of attempted conversion of ParamValues into various types:

impl Into<JsonValue> for ParamValue {
    fn into(self) -> JsonValue {
        match self {
            ParamValue::Null => JsonValue::Null,
            ParamValue::Boolean(value) => JsonValue::Bool(value),
            ParamValue::SmallInteger(value) => JsonValue::Number(value.into()),
            ParamValue::Integer(value) => JsonValue::Number(value.into()),
            ParamValue::BigInteger(value) => JsonValue::Number(value.into()),
            ParamValue::Real(value) => json!(value),
            ParamValue::BigReal(value) => json!(value),
            ParamValue::Numeric(value) => json!(value),
            ParamValue::Text(value) => JsonValue::String(value),
        }
    }
}

impl Into<JsonValue> for &ParamValue {
    fn into(self) -> JsonValue {
        self.clone().into()
    }
}

impl Into<String> for ParamValue {
    fn into(self) -> String {
        match self {
            ParamValue::Null => String::new(),
            ParamValue::Boolean(val) => val.to_string(),
            ParamValue::SmallInteger(number) => number.to_string(),
            ParamValue::Integer(number) => number.to_string(),
            ParamValue::BigInteger(number) => number.to_string(),
            ParamValue::Real(number) => number.to_string(),
            ParamValue::BigReal(number) => number.to_string(),
            ParamValue::Numeric(decimal) => decimal.to_string(),
            ParamValue::Text(string) => string.to_string(),
        }
    }
}

impl TryInto<u64> for ParamValue {
    type Error = DbError;

    fn try_into(self) -> Result<u64, DbError> {
        match self {
            ParamValue::SmallInteger(number) => {
                Ok(u64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::Integer(number) => {
                Ok(u64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::BigInteger(number) => {
                Ok(u64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            _ => Err(DbError::InputError(format!(
                "Not an unsigned integer: {self:?}"
            ))),
        }
    }
}

impl TryInto<i64> for ParamValue {
    type Error = DbError;

    fn try_into(self) -> Result<i64, DbError> {
        match self {
            ParamValue::SmallInteger(number) => {
                Ok(i64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::Integer(number) => {
                Ok(i64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::BigInteger(number) => {
                Ok(i64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            _ => Err(DbError::InputError(format!("Not an integer: {self:?}"))),
        }
    }
}

impl TryInto<f64> for ParamValue {
    type Error = DbError;

    fn try_into(self) -> Result<f64, DbError> {
        match self {
            ParamValue::Real(number) => {
                Ok(f64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::BigReal(number) => {
                Ok(f64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::Numeric(number) => {
                Ok(f64::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            _ => Err(DbError::InputError(format!("Not an integer: {self:?}"))),
        }
    }
}

impl TryInto<f32> for ParamValue {
    type Error = DbError;

    fn try_into(self) -> Result<f32, DbError> {
        match self {
            ParamValue::Real(number) => {
                Ok(f32::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            ParamValue::BigReal(number) => Ok(number as f32),
            ParamValue::Numeric(number) => {
                Ok(f32::try_from(number).map_err(|err| DbError::InputError(err.to_string()))?)
            }
            _ => Err(DbError::InputError(format!("Not an integer: {self:?}"))),
        }
    }
}

impl Into<String> for &ParamValue {
    fn into(self) -> String {
        self.clone().into()
    }
}

// Implementations of attempted conversions of various types into ParamValues:

impl From<&str> for ParamValue {
    fn from(item: &str) -> Self {
        ParamValue::Text(item.to_string())
    }
}

impl From<String> for ParamValue {
    fn from(item: String) -> Self {
        ParamValue::Text(item)
    }
}

impl From<&String> for ParamValue {
    fn from(item: &String) -> Self {
        ParamValue::Text(item.clone())
    }
}

impl From<i16> for ParamValue {
    fn from(item: i16) -> Self {
        ParamValue::SmallInteger(item)
    }
}

impl From<i32> for ParamValue {
    fn from(item: i32) -> Self {
        ParamValue::Integer(item.into())
    }
}

impl From<i64> for ParamValue {
    fn from(item: i64) -> Self {
        ParamValue::BigInteger(item)
    }
}

impl From<u16> for ParamValue {
    fn from(item: u16) -> Self {
        ParamValue::Integer(item.into())
    }
}

impl From<u32> for ParamValue {
    fn from(item: u32) -> Self {
        if usize::BITS <= 31 {
            ParamValue::Integer(item as i32)
        } else {
            ParamValue::BigInteger(item as i64)
        }
    }
}

impl From<u64> for ParamValue {
    fn from(item: u64) -> Self {
        if item <= i64::MAX as u64 {
            ParamValue::BigInteger(item as i64)
        } else {
            ParamValue::Numeric(Decimal::from(item))
        }
    }
}

impl From<isize> for ParamValue {
    fn from(item: isize) -> Self {
        if isize::BITS <= 32 {
            ParamValue::Integer(item as i32)
        } else if isize::BITS <= 64 {
            ParamValue::BigInteger(item as i64)
        } else {
            ParamValue::Numeric(Decimal::from(item))
        }
    }
}

impl From<usize> for ParamValue {
    fn from(item: usize) -> Self {
        if usize::BITS <= 31 {
            ParamValue::Integer(item as i32)
        } else if usize::BITS <= 63 {
            ParamValue::BigInteger(item as i64)
        } else {
            ParamValue::Numeric(Decimal::from(item))
        }
    }
}

impl From<f32> for ParamValue {
    fn from(item: f32) -> Self {
        ParamValue::Real(item)
    }
}

impl From<f64> for ParamValue {
    fn from(item: f64) -> Self {
        ParamValue::BigReal(item)
    }
}

impl From<Decimal> for ParamValue {
    fn from(item: Decimal) -> Self {
        ParamValue::Numeric(item)
    }
}

impl From<bool> for ParamValue {
    fn from(item: bool) -> Self {
        ParamValue::Boolean(item)
    }
}

impl From<JsonValue> for ParamValue {
    fn from(item: JsonValue) -> Self {
        match &item {
            JsonValue::Null => Self::Null,
            JsonValue::Bool(val) => Self::Boolean(*val),
            JsonValue::Number(number) => {
                if number.is_u64() {
                    Self::from(number.as_u64().unwrap())
                } else if number.is_i64() {
                    Self::from(number.as_i64().unwrap())
                } else if number.is_f64() {
                    Self::BigReal(number.as_f64().unwrap())
                } else {
                    Self::Text(item.to_string())
                }
            }
            JsonValue::String(string) => Self::Text(string.to_string()),
            JsonValue::Array(_) => Self::Text(item.to_string()),
            JsonValue::Object(_) => Self::Text(item.to_string()),
        }
    }
}

impl From<()> for ParamValue {
    fn from(_: ()) -> Self {
        ParamValue::Null
    }
}

// f32 and f64 don't implement PartialEq, so we have to do it ourselves.
impl PartialEq for ParamValue {
    fn eq(&self, other: &Self) -> bool {
        match (self, other) {
            (ParamValue::Null, ParamValue::Null) => true,
            (ParamValue::Boolean(a), ParamValue::Boolean(b)) => a == b,
            (ParamValue::SmallInteger(a), ParamValue::SmallInteger(b)) => a == b,
            (ParamValue::Integer(a), ParamValue::Integer(b)) => a == b,
            (ParamValue::BigInteger(a), ParamValue::BigInteger(b)) => a == b,
            (ParamValue::Real(a), ParamValue::Real(b)) => {
                if a.is_finite() && b.is_finite() {
                    a == b
                } else {
                    false
                }
            }
            (ParamValue::BigReal(a), ParamValue::BigReal(b)) => {
                if a.is_finite() && b.is_finite() {
                    a == b
                } else {
                    false
                }
            }
            (ParamValue::Numeric(a), ParamValue::Numeric(b)) => a == b,
            (ParamValue::Text(a), ParamValue::Text(b)) => a == b,
            _ => false,
        }
    }
}

impl Eq for ParamValue {}

/// Types that implement this trait can be converted into a [ParamValue].
pub trait IntoParamValue {
    fn into_param_value(self) -> ParamValue;
}

/// Implements [IntoParamValue] for types that implement [TryFrom] for [ParamValue].
impl<T: Into<ParamValue>> IntoParamValue for T {
    fn into_param_value(self) -> ParamValue {
        self.into()
    }
}

/// Query parameters
#[derive(Debug, Clone)]
pub enum Params {
    None,
    Positional(Vec<ParamValue>),
}

/// Types that implement this trait can be converted into [Params]
pub trait IntoParams {
    fn into_params(self) -> Params;
}

/// (Trivially) implements [IntoParams] for [Params]
impl IntoParams for Params {
    fn into_params(self) -> Params {
        self
    }
}

/// Implements [IntoParams] for references to [Params]
impl IntoParams for &Params {
    fn into_params(self) -> Params {
        self.clone()
    }
}

/// Implements [IntoParams] for an empty tuple. Always returns [Params::None].
impl IntoParams for () {
    fn into_params(self) -> Params {
        Params::None
    }
}

/// Implements [IntoParams] for fixed-length arrays of types that implement [IntoParamValue]
impl<T: IntoParamValue, const N: usize> IntoParams for [T; N] {
    fn into_params(self) -> Params {
        self.into_iter().collect::<Vec<_>>().into_params()
    }
}

/// Implements [IntoParams] for references to fixed-length arrays of types that implement
/// [IntoParamValue]
impl<T: IntoParamValue + Clone, const N: usize> IntoParams for &[T; N] {
    fn into_params(self) -> Params {
        self.iter().cloned().collect::<Vec<_>>().into_params()
    }
}

/// Implements [IntoParams] for vectors of types that implement [IntoParamValue]
impl<T: IntoParamValue> IntoParams for Vec<T> {
    fn into_params(self) -> Params {
        let values = self
            .into_iter()
            .map(|i| i.into_param_value())
            .collect::<Vec<_>>();
        Params::Positional(values)
    }
}

/// Converts a list of assorted types implementing [IntoParamValue] into [Params]
#[macro_export]
macro_rules! params {
    () => {
       ()
    };
    ($($value:expr),* $(,)?) => {{
        use $crate::core::IntoParamValue;
        [$($value.into_param_value()),*]

    }};
}

// Traits for converting to and from vectors of DbRows:

pub trait IntoDbRows {
    fn into_db_rows(self) -> Vec<DbRow>;
}

impl IntoDbRows for Vec<DbRow> {
    fn into_db_rows(self) -> Vec<DbRow> {
        self
    }
}

impl IntoDbRows for &Vec<DbRow> {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.clone()
    }
}

impl IntoDbRows for &[DbRow] {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.to_vec()
    }
}

impl IntoDbRows for &[&DbRow] {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.into_iter()
            .cloned()
            .map(|row| row.clone())
            .collect::<Vec<_>>()
    }
}

impl<const N: usize> IntoDbRows for &[&DbRow; N] {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.into_iter()
            .cloned()
            .map(|row| row.clone())
            .collect::<Vec<_>>()
    }
}

impl IntoDbRows for Vec<JsonRow> {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.into_iter()
            .map(|row| {
                row.into_iter()
                    .map(|(key, val)| (key, ParamValue::from(val)))
                    .collect()
            })
            .collect::<Vec<_>>()
    }
}

impl IntoDbRows for &Vec<JsonRow> {
    fn into_db_rows(self) -> Vec<DbRow> {
        self.clone().into_db_rows()
    }
}

pub trait FromDbRows {
    fn from(rows: Vec<DbRow>) -> Self;
}

impl FromDbRows for Vec<JsonRow> {
    fn from(rows: Vec<DbRow>) -> Self {
        rows.into_iter()
            .map(|row| {
                row.into_iter()
                    .map(|(key, val)| (key, val.into()))
                    .collect()
            })
            .collect::<Vec<_>>()
    }
}

impl FromDbRows for Vec<DbRow> {
    fn from(rows: Vec<DbRow>) -> Self {
        rows
    }
}

/// Strategy to use when caching query results
#[derive(Clone, Copy, Debug, Eq, PartialEq)]
pub enum CachingStrategy {
    /// No Caching.
    None,
    /// Truncate the entire cache when it is dirty.
    TruncateAll,
    /// Truncate entries only for edited tables when the cache is dirty.
    Truncate,
    /// Truncate cache entries, for edited tables only, automatically whenever tables are edited.
    Trigger,
    /// Similar to Truncate, but use an in-memory cache.
    Memory(usize),
}

/// The structure used to look up query results in the in-memory cache:
#[derive(Clone, Eq, PartialEq, Hash)]
pub struct MemoryCacheKey {
    pub tables: String,
    pub statement: String,
    pub parameters: String,
}

impl FromStr for CachingStrategy {
    type Err = DbError;

    fn from_str(strategy: &str) -> Result<Self, DbError> {
        match strategy.to_lowercase().as_str() {
            "none" => Ok(CachingStrategy::None),
            "truncate_all" => Ok(CachingStrategy::TruncateAll),
            "truncate" => Ok(CachingStrategy::Truncate),
            "trigger" => Ok(CachingStrategy::Trigger),
            strategy if strategy.starts_with("memory") => {
                let elems = strategy.split(":").collect::<Vec<_>>();
                let cache_size = {
                    if elems.len() < 2 {
                        DEFAULT_MEMORY_CACHE_SIZE
                    } else {
                        let cache_size = elems[1];
                        match cache_size.parse::<usize>() {
                            Ok(0) => DEFAULT_MEMORY_CACHE_SIZE,
                            Ok(size) => size,
                            Err(err) => return Err(DbError::InputError(format!(
                                "Error parsing memory cache size specification: '{cache_size}': \
                                 {err}"
                            ))
                            .into()),
                        }
                    }
                };
                Ok(CachingStrategy::Memory(cache_size))
            }
            _ => {
                return Err(
                    DbError::InputError(format!("Unrecognized strategy: {strategy}")).into(),
                );
            }
        }
    }
}

impl Display for CachingStrategy {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            CachingStrategy::None => write!(f, "none"),
            CachingStrategy::TruncateAll => write!(f, "truncate_all"),
            CachingStrategy::Truncate => write!(f, "truncate"),
            CachingStrategy::Trigger => write!(f, "trigger"),
            CachingStrategy::Memory(size) => write!(f, "memory:{size}"),
        }
    }
}

#[async_trait]
pub trait DbQuery {
    /// Get the kind of SQL database: SQLite or PostgreSQL.
    fn kind(&self) -> DbKind;

    /// Set the caching strategy.
    fn set_caching_strategy(&mut self, strategy: &CachingStrategy);

    /// Get the current caching strategy.
    fn get_caching_strategy(&self) -> CachingStrategy;

    /// When turned on, and the current [CachingStrategy] is not [None](CachingStrategy::None),
    /// SQL commands executed through the API will be automatically checked to see if they
    /// involve edits and/or drops of database tables. If they do then the cache will be
    /// automatically updated in accordance with the current [CachingStrategy].
    fn set_cache_aware_query(&mut self, value: bool);

    /// Returns true if the cache_aware_query option is currently on.
    fn get_cache_aware_query(&self) -> bool;

    /// Ensure that the cache table exists
    fn ensure_cache_table_exists(&self) -> impl Future<Output = Result<(), DbError>> + Send;

    /// Ensure that caching triggers exist for the given tables. Note that this function calls
    /// [DbQuery::ensure_cache_table_exists()] implicitly.
    fn ensure_caching_triggers_exist(
        &self,
        tables: &[&str],
    ) -> impl Future<Output = Result<(), DbError>> + Send;

    /// Parse the given semi-colon-separated SQL commands and determine which tables will be
    /// affected (either edited or dropped) by the commands, then ensure that there are no
    /// entries for those tables in the cache in accordance with the current [CachingStrategy].
    async fn clear_cache_for_affected_tables(&self, sql: &str) -> Result<(), DbError> {
        if self.get_caching_strategy() != CachingStrategy::None {
            let (edited_tables, dropped_tables): (Vec<_>, Vec<_>) = {
                let (edited_tables, dropped_tables) = get_affected_tables(sql)?;
                (
                    edited_tables.into_iter().collect(),
                    dropped_tables.into_iter().collect(),
                )
            };
            if !edited_tables.is_empty() {
                let edited_tables: Vec<_> = edited_tables.iter().map(|t| t.as_str()).collect();
                self.clear_cache_for_edited_tables(&edited_tables).await?;
            }
            if !dropped_tables.is_empty() {
                let dropped_tables: Vec<_> = dropped_tables.iter().map(|t| t.as_str()).collect();
                self.clear_cache_for_dropped_tables(&dropped_tables).await?;
            }
        }
        Ok(())
    }

    // Triggers cannot apply to DROP commands, only to INSERT, UPDATE, DELETE, or TRUNCATE.
    // See https://www.postgresql.org/docs/current/sql-createtrigger.html and
    // https://sqlite.org/lang_createtrigger.html. Note that PostgreSQL has the concept
    // of an "event trigger":
    // https://www.pgtutorial.com/postgresql-tutorial/postgresql-event-triggers/ which could
    // be used, but SQLite has no such capability. To workaround the limitation in SQLite, we
    // define two clear_cache_() functions, one for edited tables, and one for dropped tables.
    // In the case of a dropped table, unlike an edit, we cannot rely on the caching trigger,
    // when we are using the [CachingStategy::Trigger] strategy, to automatically delete the
    // entries from the cache for those tables, since those triggers will have beeen dropped
    // along with the table.
    // Although strictly speaking, PostgreSQL (which has event triggers) is not subject to this
    // limitation, for simplicity we will not be creating a PostgreSQL event trigger and we will
    // use both functions below for both database types.

    /// Clear the entries from the cache table for the given list of tables, using the
    /// current [CachingStrategy], under the assumption that the tables in the given list have
    /// all just been edited (i.e., truncated, deleted from, inserted to, or updated).
    async fn clear_cache_for_edited_tables(&self, tables: &[&str]) -> Result<(), DbError> {
        match self.get_caching_strategy() {
            CachingStrategy::None | CachingStrategy::Trigger => (),
            CachingStrategy::TruncateAll => self.delete_cache_entries_for_tables(&[]).await?,
            CachingStrategy::Truncate => self.delete_cache_entries_for_tables(tables).await?,
            CachingStrategy::Memory(_) => clear_mem_cache(&tables)?,
        };
        Ok(())
    }

    /// Clear the entries from the cache table for the given list of tables, using the
    /// current [CachingStrategy], under the assumption that the tables in the given list have
    /// all just been dropped.
    async fn clear_cache_for_dropped_tables(&self, tables: &[&str]) -> Result<(), DbError> {
        match self.get_caching_strategy() {
            CachingStrategy::None => (),
            CachingStrategy::TruncateAll => self.delete_cache_entries_for_tables(&[]).await?,
            CachingStrategy::Trigger | CachingStrategy::Truncate => {
                self.delete_cache_entries_for_tables(tables).await?
            }
            CachingStrategy::Memory(_) => clear_mem_cache(&tables)?,
        };

        // Indicate that any triggers for these tables no longer exist.
        let mut meta_cache = get_meta_cache()?;
        for table in tables {
            if *table == "cache" {
                meta_cache.remove("cache_table");
            } else {
                meta_cache.remove(&format!("{table}_triggers"));
            }
        }
        Ok(())
    }

    /// Delete the entries for the tables in the given list (independently of the current
    /// caching strategy) from the cache table, if it exists. If the given table list is empty,
    /// clear the entire cache.
    async fn delete_cache_entries_for_tables(&self, tables: &[&str]) -> Result<(), DbError> {
        if self.table_exists("cache").await? {
            if tables.is_empty() {
                self.execute(r#"DELETE FROM "cache""#, ()).await?;
            } else {
                let prefix = match self.kind() {
                    DbKind::SQLite => "?",
                    DbKind::PostgreSQL => "$",
                };
                for table in tables {
                    let table = format!(r#"%{table}%"#);
                    self.execute(
                        &format!(r#"DELETE FROM "cache" WHERE "tables" LIKE {prefix}1"#),
                        &[table],
                    )
                    .await?;
                }
            }
        }
        Ok(())
    }

    /// Execute a SQL command, returning a vector of rows. If the result of the command exists
    /// in the cache, get the value from it instead of from the table(s) actually mentioned in the
    /// command, using the given [CachingStrategy].
    async fn cache<T: FromDbRows>(
        &self,
        tables: &[&str],
        sql: &str,
        params: impl IntoParams + Send + Copy + Sync,
    ) -> Result<T, DbError> {
        let db_cache =
            async |tables: &[&str], sql: &str, params: &Params| -> Result<Vec<DbRow>, DbError> {
                // Look in the cache to see if there is an entry corresponding to the given SQL
                // string for the given tables and parameters. If so, return the data from the
                // cache, otherwise execute the given SQL statement on the actualy specified
                // tables.
                let tables_cast = match self.kind() {
                    DbKind::SQLite => r#"CAST("tables" AS TEXT)"#,
                    DbKind::PostgreSQL => r#""tables"::TEXT"#,
                };
                let prefix = match self.kind() {
                    DbKind::SQLite => "?",
                    DbKind::PostgreSQL => "$",
                };
                let cache_sql = format!(
                    r#"SELECT {prefix}1||rtrim(ltrim("value", '['), ']')||{prefix}2 AS "value"
                       FROM "cache"
                       WHERE {tables_cast} = {prefix}3
                       AND "statement" = {prefix}4
                       AND "parameters" = {prefix}5
                       LIMIT 1"#
                );
                let tables_param = format!("[{}]", tables.join(", "));
                let params_param = match params {
                    Params::None => "[]".to_string(),
                    Params::Positional(params) => {
                        let params = params.iter().map(|p| p.into()).collect::<Vec<String>>();
                        format!("[{}]", params.join(", "))
                    }
                };
                let cache_params = &["[", "]", &tables_param, sql, &params_param];

                let strings = {
                    let rows: Vec<DbRow> = self.query_no_cache(&cache_sql, cache_params).await?;
                    let strings = rows
                        .iter()
                        .map(|row| match row.values().nth(0) {
                            Some(value) => Ok(value.into()),
                            None => Err(DbError::DataError("Empty row".to_owned())),
                        })
                        .collect::<Vec<_>>();
                    let strings: Result<Vec<String>, DbError> = strings.into_iter().collect();
                    strings?
                };
                match strings.first() {
                    Some(values) => {
                        let json_rows: Vec<JsonRow> = match serde_json::from_str(&values) {
                            Ok(json_rows) => json_rows,
                            _ => {
                                return Err(DbError::DataError(format!(
                                    "Invalid cache values: {values}"
                                )));
                            }
                        };
                        let db_rows = json_rows.into_db_rows();
                        Ok(db_rows)
                    }
                    None => {
                        let db_rows: Vec<DbRow> = self.query_no_cache(sql, params).await?;
                        let json_rows: Vec<JsonRow> = FromDbRows::from(db_rows.clone());
                        let json_rows_content = json!(json_rows).to_string();
                        let insert_sql = format!(
                            r#"INSERT INTO "cache"
                               ("tables", "statement", "parameters", "value")
                               VALUES ({prefix}1, {prefix}2, {prefix}3, {prefix}4)"#
                        );
                        let insert_params = [&tables_param, sql, &params_param, &json_rows_content];
                        self.execute_no_cache(&insert_sql, &insert_params).await?;
                        Ok(db_rows)
                    }
                }
            };

        let mem_cache = async |tables: &[&str],
                               sql: &str,
                               params: &Params,
                               cache_size: usize|
               -> Result<Vec<DbRow>, DbError> {
            let params = &params.into_params();
            let mem_key = MemoryCacheKey {
                tables: tables.join(", ").to_string(),
                statement: sql.to_string(),
                parameters: format!("{params:?}"),
            };
            let cached_rows = {
                let cache = get_memory_cache()?;
                match cache.get(&mem_key) {
                    Some(json_rows) => Some(json_rows.to_vec()),
                    None => None,
                }
            };
            match cached_rows {
                Some(json_rows) => {
                    let db_rows = json_rows.into_db_rows();
                    Ok(db_rows)
                }
                None => {
                    let db_rows: Vec<DbRow> = self.query_no_cache(sql, params).await?;
                    let json_rows: Vec<JsonRow> = FromDbRows::from(db_rows.clone());
                    let mut cache = get_memory_cache()?;
                    let mut keys = cache.keys().map(|key| key.clone()).collect::<Vec<_>>();
                    // If the number of keys exceeds the allowed cache size, remove any extra keys
                    // at random.
                    if keys.len() >= cache_size {
                        keys.shuffle(&mut rand::rng());
                        for (i, key) in keys.iter().enumerate().rev() {
                            if i >= (cache_size - 1) {
                                cache.remove(&key);
                            } else {
                                break;
                            }
                        }
                    }
                    cache.insert(mem_key, json_rows.to_vec());
                    Ok(db_rows)
                }
            }
        };

        match self.get_caching_strategy() {
            CachingStrategy::None => {
                let rows: Vec<DbRow> = self.query_no_cache(sql, params).await?;
                Ok(FromDbRows::from(rows))
            }
            CachingStrategy::TruncateAll | CachingStrategy::Truncate => {
                let cache_table_exists = match get_meta_cache()?.get("cache_table") {
                    Some(_) => true,
                    None => false,
                };
                if !cache_table_exists {
                    self.ensure_cache_table_exists().await?;
                    let mut cache = get_meta_cache()?;
                    cache.insert("cache_table".to_string());
                }
                let rows: Vec<DbRow> = db_cache(tables, sql, &params.into_params()).await?;
                Ok(FromDbRows::from(rows))
            }
            CachingStrategy::Trigger => {
                for table in tables {
                    let table_triggers = format!("{table}_triggers");
                    let table_triggers_exist = match get_meta_cache()?.get(&table_triggers) {
                        Some(_) => true,
                        None => false,
                    };
                    if !table_triggers_exist {
                        self.ensure_caching_triggers_exist(&[table]).await?;
                        let mut cache = get_meta_cache()?;
                        cache.insert(table_triggers);
                    }
                }
                let rows: Vec<DbRow> = db_cache(tables, sql, &params.into_params()).await?;
                Ok(FromDbRows::from(rows))
            }
            CachingStrategy::Memory(cache_size) => {
                let rows = mem_cache(tables, sql, &params.into_params(), cache_size).await?;
                Ok(FromDbRows::from(rows))
            }
        }
    }

    /// Given a SQL type for this database and a string,
    /// parse the string into the right ParamValue.
    fn parse(&self, sql_type: &str, value: &str) -> Result<ParamValue, DbError>;

    /// Given a table, return a map from column names to column SQL types.
    fn columns(&self, table: &str) -> impl Future<Output = Result<ColumnMap, DbError>> + Send;

    // TODO: Consider combining this function with columns().
    /// Retrieve the primary key columns for a given table.
    fn primary_keys(
        &self,
        table: &str,
    ) -> impl Future<Output = Result<Vec<String>, DbError>> + Send;

    /// Execute a SQL command, returning nothing.
    async fn execute(&self, sql: &str, params: impl IntoParams + Send) -> Result<(), DbError> {
        let params = params.into_params();
        let _: Vec<DbRow> = match params {
            Params::None => self.query(sql, ()).await?,
            _ => self.query(sql, params).await?,
        };
        Ok(())
    }

    /// Execute a SQL command, returning nothing, without updating the cache, regardless of
    /// whether cache_aware_query option (see [DbQuery::set_cache_aware_query()]) has been set.
    async fn execute_no_cache(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<(), DbError> {
        let params = params.into_params();
        let _: Vec<DbRow> = match params {
            Params::None => self.query_no_cache(sql, ()).await?,
            _ => self.query_no_cache(sql, params).await?,
        };
        Ok(())
    }

    /// Sequentially execute a semicolon-delimited list of statements, without parameters.
    fn execute_batch(&self, sql: &str) -> impl Future<Output = Result<(), DbError>> + Send;

    /// Execute a SQL command, returning a vector of rows.
    async fn query<T: FromDbRows + Send>(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<T, DbError> {
        let rows = self.query_no_cache(sql, params).await?;
        if self.get_cache_aware_query() {
            self.clear_cache_for_affected_tables(sql).await?;
        }
        Ok(rows)
    }

    /// Execute a SQL command, returning a vector of rows, without updating the cache,
    /// regardless of whether the cache_aware_query option (see [DbQuery::set_cache_aware_query()])
    /// has been set.
    fn query_no_cache<T: FromDbRows>(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> impl Future<Output = Result<T, DbError>> + Send;

    /// Execute a SQL command, returning a single row.
    async fn query_row(&self, sql: &str, params: impl IntoParams + Send) -> Result<DbRow, DbError> {
        let rows: Vec<DbRow> = self.query(&sql, params).await?;
        if rows.len() > 1 {
            return Err(DbError::DataError(
                "More than one row returned for query_row()".to_string(),
            ));
        }
        match rows.into_iter().next() {
            Some(row) => Ok(row),
            None => Err(DbError::DataError("No row found".to_string())),
        }
    }

    /// Execute a SQL command, returning a single value.
    async fn query_value(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<ParamValue, DbError> {
        let row = self.query_row(sql, params).await?;
        if row.len() > 1 {
            return Err(DbError::DataError(
                "More than one value returned for query_value()".to_string(),
            ));
        }
        match row.values().next() {
            Some(value) => Ok(value.clone()),
            None => Err(DbError::DataError("No values found".to_string())),
        }
    }

    /// Execute a SQL command, returning a single string.
    async fn query_string(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<String, DbError> {
        let value = self.query_value(sql, params).await?;
        Ok(value.into())
    }

    /// Execute a SQL command, returning a vector of strings: the first value for each row.
    async fn query_strings(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<Vec<String>, DbError> {
        let rows: Vec<DbRow> = self.query(sql, params).await?;
        rows.iter()
            .map(|row| match row.values().nth(0) {
                Some(value) => Ok(value.into()),
                None => Err(DbError::DataError("Empty row".to_owned())),
            })
            .collect()
    }

    /// Execute a SQL command, returning a row of strings.
    async fn query_string_row(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<StringRow, DbError> {
        let row = self.query_row(sql, params).await?;
        Ok(row
            .iter()
            .map(|(key, value)| (key.clone(), value.into()))
            .collect())
    }

    /// Execute a SQL command, returning a vector of rows of strings.
    async fn query_string_rows(
        &self,
        sql: &str,
        params: impl IntoParams + Send,
    ) -> Result<Vec<StringRow>, DbError> {
        let rows: Vec<DbRow> = self.query(sql, params).await?;
        Ok(db_rows_to_string_rows(&rows))
    }

    /// Execute a SQL command, returning a single unsigned integer.
    async fn query_u64(&self, sql: &str, params: impl IntoParams + Send) -> Result<u64, DbError> {
        let value = self.query_value(sql, params).await?;
        Ok(value.try_into()?)
    }

    /// Execute a SQL command, returning a single signed integer.
    async fn query_i64(&self, sql: &str, params: impl IntoParams + Send) -> Result<i64, DbError> {
        let value = self.query_value(sql, params).await?;
        Ok(value.try_into()?)
    }

    /// Execute a SQL command, returning a single float.
    async fn query_f64(&self, sql: &str, params: impl IntoParams + Send) -> Result<f64, DbError> {
        let value = self.query_value(sql, params).await?;
        Ok(value.try_into()?)
    }

    /// Insert rows into the given table. If an input row does not have a key for a column,
    /// use NULL as the value of that column when inserting the row to the table.
    fn insert(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
    ) -> impl Future<Output = Result<(), DbError>>;

    /// Like [DbQuery::insert()], but in addition this function also returns the columns from the
    /// inserted data that are included in `returning`, or all of the inserted data if `returning`
    /// is an empty list.
    fn insert_returning<T: FromDbRows>(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
        returning: &[&str],
    ) -> impl Future<Output = Result<T, DbError>>;

    /// Update the given table using the given rows. The table should have a primary key
    /// and any columns included in the primary key should be present within each input row.
    /// The primary key column values will be used as a way of identifying the rows to update,
    /// while the other columns in the row will be updated to the given new values.
    fn update(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
    ) -> impl Future<Output = Result<(), DbError>>;

    /// Like [DbQuery::update()], but in addition this function also returns the columns from the
    /// updated data that are included in `returning`, or all of the updated data if `returning`
    /// is an empty list.
    fn update_returning<T: FromDbRows>(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
        returning: &[&str],
    ) -> impl Future<Output = Result<T, DbError>>;

    /// Attempt to insert the given rows to the given table, similarly to [DbQuery::insert()].
    /// In case there is a conflict, update the table instead, similarly to [DbQuery::update()].
    fn upsert(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
    ) -> impl Future<Output = Result<(), DbError>>;

    /// Like [DbQuery::upsert()], but in addition this function also returns the columns from the
    /// upserted data that are included in `returning`, or all of the upserted data if `returning`
    /// is an empty list.
    fn upsert_returning<T: FromDbRows>(
        &self,
        table: &str,
        columns: &[&str],
        rows: impl IntoDbRows,
        returning: &[&str],
    ) -> impl Future<Output = Result<T, DbError>>;

    /// Check whether the given table exists in the database.
    fn table_exists(&self, table: &str) -> impl Future<Output = Result<bool, DbError>> + Send;

    /// Drop the given table from the database. Note that for PostgreSQL (see
    /// <https://www.postgresql.org/docs/current/sql-droptable.html>), in the case of a
    /// dependent foreign key constraint, only the constraint will be removed, not the dependent
    /// table itself.
    async fn drop_table(&self, table: &str) -> Result<(), DbError> {
        let table = validate_table_name(table)?;
        // Drop the table:
        match self.kind() {
            DbKind::PostgreSQL => {
                self.execute_no_cache(&format!(r#"DROP TABLE IF EXISTS "{table}" CASCADE"#), ())
                    .await?
            }
            DbKind::SQLite => {
                self.execute_no_cache(&format!(r#"DROP TABLE IF EXISTS "{table}""#), ())
                    .await?
            }
        };

        // Delete dirty entries from the cache in accordance with our caching strategy:
        self.clear_cache_for_dropped_tables(&[&table]).await?;
        Ok(())
    }
}

/// Convert a [DbRow] into a [StringRow]
pub fn db_row_to_string_row(row: &DbRow) -> StringRow {
    row.iter()
        .map(|(key, value)| (key.clone(), value.into()))
        .collect()
}

/// Convert a vector of [DbRow]s into a vector of [StringRow]s.
pub fn db_rows_to_string_rows(rows: &[DbRow]) -> Vec<StringRow> {
    rows.iter().map(|row| db_row_to_string_row(row)).collect()
}

/// Determines whether the given table name is a valid database table name. Valid database table
/// names must match the regular expression: `^[A-Za-z_\]\[0-9A-Za-z_]*$`. For convenience, a
/// double-quoted valid table name is also accepted as valid. The function returns the table name,
/// if valid, with the surrounding double-quotes (if any) removed, or an error if the table name is
/// invalid.
pub fn validate_table_name(table_name: &str) -> Result<String, DbError> {
    let error_msg = format!(
        "Not a valid table name: \"{table_name}\". Valid table names must match \
         the regular expression: '{VALID_TABLE_NAME_MATCH_STR}' and may possibly begin and \
         end with double-quotes."
    );
    let table_name = match table_name.strip_prefix("\"") {
        Some(table_name) => match table_name.strip_suffix("\"") {
            Some(table_name) => table_name,
            None => return Err(DbError::InputError(error_msg)),
        },
        None => match table_name.strip_suffix("\"") {
            Some(_) => return Err(DbError::InputError(error_msg)),
            None => table_name,
        },
    };
    match VALID_TABLE_NAME_REGEX.is_match(table_name) {
        true => Ok(table_name.to_string()),
        false => Err(DbError::InputError(error_msg)),
    }
}

/// Parse the given string, representing a series of (semi-colon-separated) SQL commands,
/// into their constituents and determine the tables that will be affected when the commands
/// are executed, if any. Two sets of tables are returned. The first contains the tables that
/// are going to be edited (targets of commands like INSERT, UPDATE, DELETE, and TRUNCATE), the
/// second contains tables that are going to be dropped (targets of a DROP TABLE command).
/// All other kinds of statements will be silently ignored. In particular, table modifications
/// that occur _within_ a CTE are not recognized by this function. Such table-modifying CTEs are
/// supported by PostgreSQL (see
/// <https://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-MODIFYING>) but
/// seemingly not by SQLite (see <https://sqlite.org/lang_with.html>).
fn get_affected_tables(sql: &str) -> Result<(HashSet<String>, HashSet<String>), DbError> {
    // Validates that a given node is not an error node:
    let check_for_error = |node: &Node<'_>| -> Result<(), DbError> {
        if node.is_error() {
            return Err(DbError::ParseError(format!(
                "Error parsing '{sql}': {node}"
            )));
        }
        Ok(())
    };

    // Checks that the given node list is of the expected length:
    fn verify_list_len(node_list: &Vec<Node<'_>>, len: usize) -> Result<(), DbError> {
        if node_list.len() != len {
            return Err(DbError::ParseError(format!(
                "Wrong number of values: {}. Expected: {}",
                node_list.len(),
                len
            )));
        }
        Ok(())
    }

    // Instantiate the parser and read in the given sql string:
    let mut parser = Parser::new();
    parser
        .set_language(&SQL_LANGUAGE.into())
        .map_err(|err| DbError::ParseError(format!("Error setting language to SQL: {err}")))?;
    let tree = match parser.parse(sql, None) {
        Some(tree) => tree,
        None => return Err(DbError::ParseError(format!("Could not parse '{sql}'"))),
    };

    // Collect the top-level statements:
    let statements = {
        let root_node = tree.root_node();
        check_for_error(&root_node)?;
        if root_node.kind().to_lowercase() != "program" {
            return Err(DbError::ParseError(format!(
                "Unexpected root node kind: {}",
                root_node.kind()
            )));
        }
        root_node
            .children(&mut root_node.walk())
            .filter(|child| child.kind().to_lowercase() == "statement")
            .collect::<Vec<_>>()
    };

    // Determine the tables that will be modified:
    let mut edited_tables = HashSet::new();
    let mut dropped_tables = HashSet::new();
    for statement in &statements {
        check_for_error(&statement)?;
        for instruction in statement.children(&mut tree.walk()) {
            check_for_error(&instruction)?;
            match instruction.kind().to_lowercase().as_str() {
                "insert" => {
                    let table_name = {
                        let object_ref = instruction
                            .children(&mut instruction.walk())
                            .filter(|child| child.kind().to_lowercase() == "object_reference")
                            .collect::<Vec<_>>();
                        verify_list_len(&object_ref, 1)?;
                        let object_ref = object_ref[0];

                        let identifier = object_ref
                            .children(&mut object_ref.walk())
                            .filter(|child| child.kind().to_lowercase() == "identifier")
                            .collect::<Vec<_>>();
                        verify_list_len(&identifier, 1)?;
                        let identifier = identifier[0];

                        validate_table_name(
                            &sql.to_string()[identifier.start_byte()..identifier.end_byte()],
                        )?
                    };
                    edited_tables.insert(table_name);
                }
                "update" => {
                    let table_name = {
                        let relation = instruction
                            .children(&mut instruction.walk())
                            .filter(|child| child.kind().to_lowercase() == "relation")
                            .collect::<Vec<_>>();
                        verify_list_len(&relation, 1)?;
                        let relation = relation[0];

                        let object_ref = relation
                            .children(&mut relation.walk())
                            .filter(|child| child.kind().to_lowercase() == "object_reference")
                            .collect::<Vec<_>>();
                        verify_list_len(&object_ref, 1)?;
                        let object_ref = object_ref[0];

                        let identifier = object_ref
                            .children(&mut object_ref.walk())
                            .filter(|child| child.kind().to_lowercase() == "identifier")
                            .collect::<Vec<_>>();
                        verify_list_len(&identifier, 1)?;
                        let identifier = identifier[0];

                        validate_table_name(
                            &sql.to_string()[identifier.start_byte()..identifier.end_byte()],
                        )?
                    };
                    edited_tables.insert(table_name);
                }
                "delete" => {
                    let table_name = {
                        let details =
                            instruction
                                .next_sibling()
                                .ok_or(DbError::ParseError(format!(
                                    "No details found for '{}'",
                                    instruction.kind()
                                )))?;
                        let object_ref = details
                            .children(&mut details.walk())
                            .filter(|child| child.kind().to_lowercase() == "object_reference")
                            .collect::<Vec<_>>();
                        verify_list_len(&object_ref, 1)?;
                        let object_ref = object_ref[0];

                        let identifier = object_ref
                            .children(&mut object_ref.walk())
                            .filter(|child| child.kind().to_lowercase() == "identifier")
                            .collect::<Vec<_>>();
                        verify_list_len(&identifier, 1)?;
                        let identifier = identifier[0];

                        validate_table_name(
                            &sql.to_string()[identifier.start_byte()..identifier.end_byte()],
                        )?
                    };
                    edited_tables.insert(table_name);
                }
                "keyword_truncate" => {
                    let mut possible_next_word = instruction.next_sibling();
                    while let Some(next_word) = possible_next_word {
                        if next_word.kind().to_lowercase() == "object_reference" {
                            let identifier = next_word
                                .children(&mut next_word.walk())
                                .filter(|child| child.kind().to_lowercase() == "identifier")
                                .collect::<Vec<_>>();
                            verify_list_len(&identifier, 1)?;
                            let identifier = identifier[0];

                            let table = validate_table_name(
                                &sql.to_string()[identifier.start_byte()..identifier.end_byte()],
                            )?;
                            edited_tables.insert(table);
                        }
                        possible_next_word = next_word.next_sibling();
                    }
                }
                "drop_table" => {
                    let table_name = {
                        let object_ref = instruction
                            .children(&mut instruction.walk())
                            .filter(|child| child.kind().to_lowercase() == "object_reference")
                            .collect::<Vec<_>>();
                        verify_list_len(&object_ref, 1)?;
                        let object_ref = object_ref[0];

                        let identifier = object_ref
                            .children(&mut object_ref.walk())
                            .filter(|child| child.kind().to_lowercase() == "identifier")
                            .collect::<Vec<_>>();
                        verify_list_len(&identifier, 1)?;
                        let identifier = identifier[0];

                        validate_table_name(
                            &sql.to_string()[identifier.start_byte()..identifier.end_byte()],
                        )?
                    };
                    dropped_tables.insert(table_name);
                }
                // Silently ignore all other kinds of instructions
                _ => (),
            };
        }
    }

    // Edits of the cache table itself are never cached so we do not need to report them.
    // However we do report a drop of the cache.
    let edited_tables = edited_tables
        .into_iter()
        .filter(|table| *table != "cache")
        .collect::<HashSet<_>>();

    Ok((edited_tables, dropped_tables))
}

/// Retrieve the in-memory [MEMORY_META_CACHE].
fn get_meta_cache<'a>() -> Result<MutexGuard<'a, HashSet<String>>, DbError> {
    let max_attempts = 20;
    let mut remaining_attempts = max_attempts;
    let mut meta_cache = MEMORY_META_CACHE.try_lock();
    while let Err(err) = meta_cache {
        meta_cache = MEMORY_META_CACHE.try_lock();
        if let Ok(_) = meta_cache {
            break;
        }
        remaining_attempts -= 1;
        if remaining_attempts == 0 {
            return Err(DbError::ConnectError(format!(
                "Error locking cache: {err} (retried {max_attempts} times)"
            )));
        } else {
            thread::sleep(Duration::from_millis(5));
        }
    }
    let meta_cache = meta_cache.unwrap();
    Ok(meta_cache)
}

/// Retrieve the in-memory [MEMORY_CACHE].
fn get_memory_cache<'a>() -> Result<MutexGuard<'a, HashMap<MemoryCacheKey, Vec<JsonRow>>>, DbError>
{
    let max_attempts = 20;
    let mut remaining_attempts = max_attempts;
    let mut memory_cache = MEMORY_CACHE.try_lock();
    while let Err(err) = memory_cache {
        memory_cache = MEMORY_CACHE.try_lock();
        if let Ok(_) = memory_cache {
            break;
        }
        remaining_attempts -= 1;
        if remaining_attempts == 0 {
            return Err(DbError::ConnectError(format!(
                "Error locking cache: {err} (retried {max_attempts} times)"
            )));
        } else {
            thread::sleep(Duration::from_millis(5));
        }
    }
    let memory_cache = memory_cache.unwrap();
    Ok(memory_cache)
}

/// Retrieve a copy of the contents of the memory cache.
pub fn get_memory_cache_contents() -> Result<HashMap<MemoryCacheKey, Vec<JsonRow>>, DbError> {
    let cache = get_memory_cache()?;
    Ok(cache.clone())
}

/// Clear the memory cache.
pub fn clear_mem_cache(tables: &[&str]) -> Result<(), DbError> {
    let mut cache = get_memory_cache()?;
    let keys = cache
        .keys()
        .map(|k| k)
        .cloned()
        .collect::<HashSet<_>>()
        .into_iter()
        .collect::<Vec<_>>();
    for table in tables {
        for key in keys.iter() {
            if key.tables.contains(table) {
                cache.remove(key);
            }
        }
    }
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_table_names() {
        // Valid table names:
        assert_eq!(
            validate_table_name(r#"table"#).expect("Expected table name to be valid"),
            "table"
        );
        assert_eq!(
            validate_table_name(r#"my_table"#).expect("Expected table name to be valid"),
            "my_table"
        );
        assert_eq!(
            validate_table_name(r#"my_2nd_table"#).expect("Expected table name to be valid"),
            "my_2nd_table"
        );
        assert_eq!(
            validate_table_name(r#"my_table_2"#).expect("Expected table name to be valid"),
            "my_table_2"
        );
        assert_eq!(
            validate_table_name(r#"my_table2"#).expect("Expected table name to be valid"),
            "my_table2"
        );
        assert_eq!(
            validate_table_name(r#"My_Table_2"#).expect("Expected table name to be valid"),
            "My_Table_2"
        );

        // Valid table name surrounded by quotes:
        assert_eq!(
            validate_table_name(r#""table""#).expect("Expected table name to be valid"),
            "table"
        );

        // Invalid first character:
        if let Ok(_) = validate_table_name(r#"1table"#) {
            panic!("Expected an error");
        };
        if let Ok(_) = validate_table_name(r#""1table""#) {
            panic!("Expected an error");
        }

        // Beginning or trailing double-quote is missing:
        if let Ok(_) = validate_table_name(r#"table""#) {
            panic!("Expected an error");
        }
        if let Ok(_) = validate_table_name(r#""table"#) {
            panic!("Expected an error");
        }

        // Table name with spaces:
        if let Ok(_) = validate_table_name(r#"my table"#) {
            panic!("Expected an error");
        }
    }

    #[tokio::test]
    async fn test_sql_parsing() {
        // Single statements, possibly with parameters:

        let (edited_tables, dropped_tables) =
            get_affected_tables(&format!(r#"INSERT INTO "alpha" VALUES ($1, $2, $3)"#)).unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["alpha"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) = get_affected_tables(
            r#"WITH bar AS (SELECT * FROM alpha),
                        mar AS (SELECT * FROM beta)
                   INSERT INTO gamma
                   SELECT alpha.*
                   FROM alpha, beta
                   WHERE alpha.value = beta.value"#,
        )
        .unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["gamma"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) =
            get_affected_tables(&format!(r#"UPDATE "delta" set bar = $1 WHERE bar = $2"#)).unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["delta"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) = get_affected_tables(&format!(
            r#"WITH bar AS (SELECT * FROM test),
                        mar AS (SELECT * FROM test)
                   UPDATE delta
                   SET value = bar.value
                   FROM bar, mar
                   WHERE bar.value = $1 AND bar.value = mar.value"#,
        ))
        .unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["delta"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) =
            get_affected_tables(&format!(r#"DELETE FROM "epsilon" WHERE bar >= $1"#)).unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["epsilon"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) = get_affected_tables(
            r#"WITH bar AS (SELECT * FROM test),
                        mar AS (SELECT * FROM test)
                   DELETE FROM lambda WHERE value IN (SELECT value FROM bar)"#,
        )
        .unwrap();
        let edited_tables: Vec<_> = edited_tables.into_iter().collect();
        assert_eq!(edited_tables, ["lambda"]);
        assert_eq!(dropped_tables, [].into());

        let (edited_tables, dropped_tables) = get_affected_tables(r#"DROP TABLE "rho""#).unwrap();
        let dropped_tables: Vec<_> = dropped_tables.into_iter().collect();
        assert_eq!(dropped_tables, ["rho"]);
        assert_eq!(edited_tables, [].into());

        let (edited_tables, dropped_tables) =
            get_affected_tables(r#"DROP TABLE IF EXISTS "phi" CASCADE"#).unwrap();
        let dropped_tables: Vec<_> = dropped_tables.into_iter().collect();
        assert_eq!(dropped_tables, ["phi"]);
        assert_eq!(edited_tables, [].into());

        let (edited_tables, dropped_tables) =
            get_affected_tables("TRUNCATE TABLE mu, nu CASCADE").unwrap();
        let mut edited_tables: Vec<_> = edited_tables.into_iter().collect();
        edited_tables.sort();
        assert_eq!(edited_tables, ["mu", "nu"]);
        assert_eq!(dropped_tables, [].into());

        // Multiple statements, no parameters:

        let sql = r#"
            INSERT INTO "alpha" VALUES (1, 2, 3), (4, 5, 6);

            INSERT INTO gamma
            SELECT alpha.*
            FROM alpha, beta
            WHERE alpha.value = beta.value;

            WITH t AS (
              SELECT * from delta_base ORDER BY quality LIMIT 1
            )
            UPDATE delta SET price = t.price * 1.05;

            WITH t AS (
              SELECT * FROM phi_base
              WHERE
                "date" >= '2010-10-01' AND
                "date" < '2010-11-01'
            )
            INSERT INTO phi
            SELECT * FROM t;

            DELETE FROM "psi" WHERE bar >= 10;

            WITH RECURSIVE included_lambda(sub_lambda, lambda) AS (
                SELECT sub_lambda, lambda FROM lambda WHERE lambda = 'our_product'
              UNION ALL
                SELECT p.sub_lambda, p.lambda
                FROM included_lambda pr, lambda p
                WHERE p.lambda = pr.sub_lambda
            )
            DELETE FROM lambda
              WHERE lambda IN (SELECT lambda FROM included_lambda);

            DROP TABLE "rho";

            DROP TABLE "sigma" CASCADE"#;

        let (edited_tables, dropped_tables) = get_affected_tables(&sql).unwrap();
        let mut edited_tables: Vec<_> = edited_tables.into_iter().collect();
        let mut dropped_tables: Vec<_> = dropped_tables.into_iter().collect();
        edited_tables.sort();
        dropped_tables.sort();
        assert_eq!(
            edited_tables,
            ["alpha", "delta", "gamma", "lambda", "phi", "psi",]
        );
        assert_eq!(dropped_tables, ["rho", "sigma",]);
    }
}
